{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9fd6517-7bef-47bf-ae12-104012da542a",
   "metadata": {},
   "source": [
    "# You.com Hackathon RAG Pipeline V2 Project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffbbbff-e59f-4233-8b32-5551aa0718c8",
   "metadata": {},
   "source": [
    "This RAG Pipeline is made for You.com Agentic Hackathon. It is focused on Finance, Accounting, or just legal documents. It is a scalabel pipeline which is multi model and uses multiple LLM agents to do the work. Key Features and Architecture of the RAG Pipeline:\n",
    "\n",
    "1. LlamaParse enabled parsing of excel, word, pdf, images, and html documents. We used Llama Agentic AI based on GPT 4.1 mini for parsing 1000+ pages workflow and extracting them in markdown form.\n",
    "2. Created three RAG Agents on you.com, all based on GPT 5 mini, and used Custom Agent API to make more than 1700+ API calls during the project.\n",
    "3. Used RAG Agents to make logical document segemntation and document type tagging for metadata.\n",
    "4. Used Recursive and Semantic Chunking for the Logical Documents\n",
    "5. Created a FAISS Vector Storage for fast nearest neighbour similarlity retriever, and also because its scalable. Used Gemini 2.5 Flash for RAG LLM and BAAI/bge-large-en-v1.5 for embedding.\n",
    "6. Created an advanced Query engine which includes Hybrid Retriver, Metadata Filtering and Query Routing, Query Expansion, Rerankers, and SubQuestion Query Engine to allow more complex question handling.\n",
    "7. We then tested the RAG Pipeline against 15 Test queries\n",
    "\n",
    "We obtained following results in our evaluation:\n",
    "1. MMR: 85%\n",
    "2. HitRate@10: 100%\n",
    "3. Recall@10: 87%\n",
    "4. HitRate@8: 93%\n",
    "5. Recall@8: 84%\n",
    "6. Relative Numarical Accuracy: 100%\n",
    "7. Query Accuracy: 87% (13/15 correct answers)\n",
    "8. Average Latency: 20.46 seconds\n",
    "\n",
    "Overall, by applying you.com Agents we were able to create a competent scalable RAG pipeline which is able to process 1000+ pages worth of documents while focusing on high Relative Numerical Accuracy required for financial and legal tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701e115-20c3-49c8-ad79-028b7aba1229",
   "metadata": {},
   "source": [
    "## Document Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69961185-a300-4e25-bb67-25593c48aa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing essential llama index libraries and other libraries, we will import others later when they are used\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex, Document\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.readers.file import PDFReader\n",
    "from llama_cpp import Llama\n",
    "import requests\n",
    "import os, glob, asyncio, nest_asyncio\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "225d78f1-c839-40d6-8507-6e9373b924ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "you_key = os.getenv('YOU_API_KEY')\n",
    "gemini_key = os.getenv('GOOGLE_API_KEY')\n",
    "llama_key = os.getenv('LLAMA_CLOUD_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1212cc97-d1bc-4e8f-990c-be53f550351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04fb5f84-d630-4433-a5f8-591d3c8f90f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(\n",
    "    # The parsing mode\n",
    "    parse_mode=\"parse_page_with_agent\",\n",
    "    # The model to use\n",
    "    model=\"openai-gpt-4-1-mini\",\n",
    "    # Whether to use high resolution OCR\n",
    "    high_res_ocr=True,\n",
    "    # Adaptive long table\n",
    "    adaptive_long_table=True,\n",
    "    outlined_table_extraction=True,\n",
    "    output_tables_as_HTML=True,\n",
    "    result_type= 'markdown'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f325c143-373a-4d8a-bc82-0ea0b4c704ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 10:37:35,160 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 2274efdf-02db-4598-8cbe-0efab6f6f71e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 10:37:36,633 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2274efdf-02db-4598-8cbe-0efab6f6f71e \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 10:37:39,193 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2274efdf-02db-4598-8cbe-0efab6f6f71e \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 10:37:39,807 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/2274efdf-02db-4598-8cbe-0efab6f6f71e/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    asyncio.get_running_loop().close()\n",
    "except RuntimeError:\n",
    "    pass\n",
    "asyncio.set_event_loop(asyncio.new_event_loop())\n",
    "\n",
    "doc = parser.load_data('train/income-statement.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b9cd9a-31d0-44bd-924e-59df9c84e054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SingleStep\n",
      "\n",
      "|       | XYZ Limited                       |                                     |         | Income Statement                                      |\n",
      "| ----- | --------------------------------- | ----------------------------------- | ------- | ----------------------------------------------------- |\n",
      "|       |                                   |                                     |         | For the Years Ending \\[Dec 31, 2020 and Dec 31, 2019] |\n",
      "|       |                                   |                                     |         |                                                       |\n",
      "|       | Revenue                           |                                     | 2020    | 2019                                                  |\n",
      "|       |                                   | Sales revenue                       | 110,000 | 95,000                                                |\n",
      "|       |                                   | (Less sales returns and allowances) |         |                                                       |\n",
      "|       |                                   | Service revenue                     | 70,000  | 62,000                                                |\n",
      "|       |                                   | Interest revenue                    |         |                                                       |\n",
      "|       |                                   | Other revenue                       |         |                                                       |\n",
      "|       | Total Revenues                    |                                     | 180,000 | 157,000                                               |\n",
      "|       |                                   |                                     |         | \\[42]                                                 |\n",
      "| \\[42] | Expenses                          |                                     |         |                                                       |\n",
      "|       |                                   | Advertising                         | 1,000   | 1,000                                                 |\n",
      "|       |                                   | Bad debt                            |         |                                                       |\n",
      "|       |                                   | Commissions                         |         |                                                       |\n",
      "|       |                                   | Cost of goods sold                  | 65,000  | 63,000                                                |\n",
      "|       |                                   | Depreciation                        |         |                                                       |\n",
      "|       |                                   | Employee benefits                   |         |                                                       |\n",
      "|       |                                   | Furniture and equipment             |         | 8,000                                                 |\n",
      "|       |                                   | Insurance                           |         |                                                       |\n",
      "|       |                                   | Interest expense                    | 4,200   | 5,200                                                 |\n",
      "|       |                                   | Maintenance and repairs             |         |                                                       |\n",
      "|       |                                   | Office supplies                     |         |                                                       |\n",
      "|       |                                   | Payroll taxes                       |         |                                                       |\n",
      "|       |                                   | Rent                                |         |                                                       |\n",
      "|       |                                   | Research and development            |         |                                                       |\n",
      "|       |                                   | Salaries and wages                  | 55,000  | 55,000                                                |\n",
      "|       |                                   | Software                            |         |                                                       |\n",
      "|       |                                   | Travel                              |         |                                                       |\n",
      "|       |                                   | Utilities                           |         |                                                       |\n",
      "|       |                                   | Web hosting and domains             |         |                                                       |\n",
      "|       |                                   | Other                               | 17,460  |                                                       |\n",
      "|       | Total Expenses                    |                                     | 142,660 | 132,200                                               |\n",
      "|       |                                   |                                     |         |                                                       |\n",
      "|       |                                   | Net Income Before Taxes             | 37,340  | 24,800                                                |\n",
      "|       |                                   | Income tax expense                  | 14,936  | 9,920                                                 |\n",
      "|       |                                   |                                     |         |                                                       |\n",
      "|       | Income from Continuing Operations |                                     | 22,404  | 14,880                                                |\n",
      "|       |                                   | {42}                                |         | \\[42]                                                 |\n",
      "|       | Below-the-Line Items              |                                     |         |                                                       |\n",
      "|       |                                   | Income from discontinued operations |         |                                                       |\n",
      "|       |                                   | Effect of accounting changes        |         |                                                       |\n",
      "|       |                                   | Extraordinary items                 |         |                                                       |\n",
      "|       |                                   |                                     |         |                                                       |\n",
      "|       | Net Income                        |                                     | 22,404  | 14,880                                                |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test load\n",
    "print(doc[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ef3ad3-c914-4b9d-a1cb-ad478b8a6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extractor = {\n",
    "    \".pdf\": parser,\n",
    "    \".docx\": parser,\n",
    "    \".doc\": parser,\n",
    "    \".xlsx\": parser,\n",
    "    \".xls\": parser,\n",
    "    \".pptx\": parser,\n",
    "    \".jpg\": parser,\n",
    "    \".jpeg\": parser,\n",
    "    \".png\": parser,\n",
    "    \".html\": parser,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490bf3dc-b05b-4b8d-89d0-c958ee0215c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:07:36,512 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 9915b0ec-1425-4355-9d82-94bda4d3c50e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:07:37,228 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 1fed80a5-74a9-46d2-a1bd-4975c036a793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:07:37,745 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:37,865 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9915b0ec-1425-4355-9d82-94bda4d3c50e \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 9cf8d013-8df0-45c4-a690-672e792a83ae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:07:38,155 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id e2aa8ae7-9147-4650-9523-cc2f4e8d5372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:07:38,775 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:38,970 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1fed80a5-74a9-46d2-a1bd-4975c036a793 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 7e8a986b-6957-4ac2-ad96-2814bd134321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:07:39,276 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9cf8d013-8df0-45c4-a690-672e792a83ae \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:39,801 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/e2aa8ae7-9147-4650-9523-cc2f4e8d5372 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:40,212 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e8a986b-6957-4ac2-ad96-2814bd134321 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:40,305 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9915b0ec-1425-4355-9d82-94bda4d3c50e \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:41,427 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1fed80a5-74a9-46d2-a1bd-4975c036a793 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:41,637 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9cf8d013-8df0-45c4-a690-672e792a83ae \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:42,228 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/e2aa8ae7-9147-4650-9523-cc2f4e8d5372 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:42,561 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e8a986b-6957-4ac2-ad96-2814bd134321 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:43,679 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9915b0ec-1425-4355-9d82-94bda4d3c50e \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:44,777 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1fed80a5-74a9-46d2-a1bd-4975c036a793 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:45,225 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9cf8d013-8df0-45c4-a690-672e792a83ae \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:45,651 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/e2aa8ae7-9147-4650-9523-cc2f4e8d5372 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:46,239 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e8a986b-6957-4ac2-ad96-2814bd134321 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:48,094 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9915b0ec-1425-4355-9d82-94bda4d3c50e \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:48,795 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9915b0ec-1425-4355-9d82-94bda4d3c50e/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:49,266 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1fed80a5-74a9-46d2-a1bd-4975c036a793 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:50,132 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/e2aa8ae7-9147-4650-9523-cc2f4e8d5372 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:50,228 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9cf8d013-8df0-45c4-a690-672e792a83ae \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:50,644 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e8a986b-6957-4ac2-ad96-2814bd134321 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:54,618 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1fed80a5-74a9-46d2-a1bd-4975c036a793 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:55,531 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/e2aa8ae7-9147-4650-9523-cc2f4e8d5372 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:56,076 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e8a986b-6957-4ac2-ad96-2814bd134321 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:56,279 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9cf8d013-8df0-45c4-a690-672e792a83ae \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:56,800 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/9cf8d013-8df0-45c4-a690-672e792a83ae/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:07:59,215 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 0267fe48-ac82-4c80-9c2e-10dc6ae43f66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:07:59,905 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 3d6cf921-db75-4946-bc6a-4f19bd122980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:08:00,636 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:00,895 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/e2aa8ae7-9147-4650-9523-cc2f4e8d5372 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:01,364 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1fed80a5-74a9-46d2-a1bd-4975c036a793 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:01,541 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e8a986b-6957-4ac2-ad96-2814bd134321 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:02,053 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:02,361 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7e8a986b-6957-4ac2-ad96-2814bd134321/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:03,546 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:04,476 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:06,517 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/e2aa8ae7-9147-4650-9523-cc2f4e8d5372 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:06,926 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1fed80a5-74a9-46d2-a1bd-4975c036a793 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:07,132 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:08,052 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:09,385 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b15f5493-1582-4944-a9de-9de2fa3f3bc3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:08:10,722 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b15f5493-1582-4944-a9de-9de2fa3f3bc3 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:11,642 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:12,046 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/e2aa8ae7-9147-4650-9523-cc2f4e8d5372 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:12,353 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1fed80a5-74a9-46d2-a1bd-4975c036a793 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:12,472 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:13,172 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b15f5493-1582-4944-a9de-9de2fa3f3bc3 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:16,552 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b15f5493-1582-4944-a9de-9de2fa3f3bc3 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:17,073 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:17,575 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/e2aa8ae7-9147-4650-9523-cc2f4e8d5372 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:17,769 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1fed80a5-74a9-46d2-a1bd-4975c036a793 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:18,087 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/e2aa8ae7-9147-4650-9523-cc2f4e8d5372/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:18,303 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1fed80a5-74a9-46d2-a1bd-4975c036a793/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:18,490 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:21,069 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b15f5493-1582-4944-a9de-9de2fa3f3bc3 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:22,910 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 91e7e30a-86d6-40d4-8bcc-69a156bbb967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:08:23,935 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:24,949 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:25,256 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:25,563 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 59fa2279-5718-4f60-84db-8c3ce2845027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:08:26,485 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b15f5493-1582-4944-a9de-9de2fa3f3bc3 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:26,963 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/59fa2279-5718-4f60-84db-8c3ce2845027 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:27,407 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:29,352 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:29,355 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/59fa2279-5718-4f60-84db-8c3ce2845027 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:30,888 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:31,092 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:32,015 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b15f5493-1582-4944-a9de-9de2fa3f3bc3 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:32,748 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/59fa2279-5718-4f60-84db-8c3ce2845027 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:34,985 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:35,496 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:36,316 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:37,136 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/59fa2279-5718-4f60-84db-8c3ce2845027 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:40,327 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b15f5493-1582-4944-a9de-9de2fa3f3bc3 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:40,333 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:40,903 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:40,911 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b15f5493-1582-4944-a9de-9de2fa3f3bc3/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:42,076 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:43,022 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/59fa2279-5718-4f60-84db-8c3ce2845027 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:43,286 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 53749373-672d-47ad-ad94-ff88b5811fba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:08:44,857 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/53749373-672d-47ad-ad94-ff88b5811fba \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:45,841 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:08:46,557 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:47,204 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/53749373-672d-47ad-ad94-ff88b5811fba \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:47,888 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:08:48,401 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/59fa2279-5718-4f60-84db-8c3ce2845027 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:50,577 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/53749373-672d-47ad-ad94-ff88b5811fba \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:51,217 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:52,189 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:53,519 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:54,749 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/59fa2279-5718-4f60-84db-8c3ce2845027 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:54,955 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/53749373-672d-47ad-ad94-ff88b5811fba \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:55,452 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/53749373-672d-47ad-ad94-ff88b5811fba/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:56,592 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:57,526 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:08:58,837 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:00,309 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/59fa2279-5718-4f60-84db-8c3ce2845027 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:00,810 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:00,910 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/59fa2279-5718-4f60-84db-8c3ce2845027/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b0cb2d7c-efa9-42b4-9b31-d5bc89d31e48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:09:02,125 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:02,690 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b0cb2d7c-efa9-42b4-9b31-d5bc89d31e48 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:02,848 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:04,280 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:05,043 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b0cb2d7c-efa9-42b4-9b31-d5bc89d31e48 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:07,671 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:08,131 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 1680729d-74c6-4d6b-8cc1-90e425a01cf1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:09:08,455 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:08,991 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b0cb2d7c-efa9-42b4-9b31-d5bc89d31e48 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:09,054 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/91e7e30a-86d6-40d4-8bcc-69a156bbb967/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:09,460 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1680729d-74c6-4d6b-8cc1-90e425a01cf1 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:09,759 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:11,809 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1680729d-74c6-4d6b-8cc1-90e425a01cf1 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:12,791 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id cd8ba7c7-5795-4aa3-be96-fe660c2ef5aa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:09:13,103 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:13,761 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b0cb2d7c-efa9-42b4-9b31-d5bc89d31e48 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:14,121 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cd8ba7c7-5795-4aa3-be96-fe660c2ef5aa \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:14,411 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b0cb2d7c-efa9-42b4-9b31-d5bc89d31e48/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:15,099 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:15,793 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1680729d-74c6-4d6b-8cc1-90e425a01cf1 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:16,536 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cd8ba7c7-5795-4aa3-be96-fe660c2ef5aa \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:18,547 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:19,485 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id fb5693fd-a2eb-4270-a409-b0008abdd3a9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:09:19,941 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cd8ba7c7-5795-4aa3-be96-fe660c2ef5aa \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:20,248 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1680729d-74c6-4d6b-8cc1-90e425a01cf1 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:20,478 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:20,865 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fb5693fd-a2eb-4270-a409-b0008abdd3a9 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:23,240 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fb5693fd-a2eb-4270-a409-b0008abdd3a9 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:23,935 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:26,255 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cd8ba7c7-5795-4aa3-be96-fe660c2ef5aa \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:26,261 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1680729d-74c6-4d6b-8cc1-90e425a01cf1 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:26,584 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:26,997 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/cd8ba7c7-5795-4aa3-be96-fe660c2ef5aa/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:27,314 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fb5693fd-a2eb-4270-a409-b0008abdd3a9 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:29,567 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:31,329 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 0f0acdfa-bceb-48fb-a276-897505c07297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:09:31,723 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1680729d-74c6-4d6b-8cc1-90e425a01cf1 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:31,725 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fb5693fd-a2eb-4270-a409-b0008abdd3a9 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:32,029 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:32,331 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/1680729d-74c6-4d6b-8cc1-90e425a01cf1/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:32,680 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0f0acdfa-bceb-48fb-a276-897505c07297 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:35,301 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:35,404 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0f0acdfa-bceb-48fb-a276-897505c07297 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:37,437 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:38,757 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0f0acdfa-bceb-48fb-a276-897505c07297 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:39,138 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fb5693fd-a2eb-4270-a409-b0008abdd3a9 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:39,674 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/fb5693fd-a2eb-4270-a409-b0008abdd3a9/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:40,831 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:09:41,548 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 7cd8e685-deea-4afb-9b59-e78f9348fc09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:09:42,991 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:43,000 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7cd8e685-deea-4afb-9b59-e78f9348fc09 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:43,471 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0267fe48-ac82-4c80-9c2e-10dc6ae43f66/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:43,676 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0f0acdfa-bceb-48fb-a276-897505c07297 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:46,214 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7cd8e685-deea-4afb-9b59-e78f9348fc09 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:46,255 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:46,488 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id bdf465f1-10a9-439c-b7d9-c4d2c30a2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:09:46,956 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 04333b76-4059-41a4-9a6f-59eb8fd741ee\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:09:47,937 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bdf465f1-10a9-439c-b7d9-c4d2c30a2032 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:48,410 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/04333b76-4059-41a4-9a6f-59eb8fd741ee \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:49,655 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7cd8e685-deea-4afb-9b59-e78f9348fc09 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:50,355 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bdf465f1-10a9-439c-b7d9-c4d2c30a2032 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:50,765 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/04333b76-4059-41a4-9a6f-59eb8fd741ee \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:51,272 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0f0acdfa-bceb-48fb-a276-897505c07297 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:51,810 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:52,103 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/0f0acdfa-bceb-48fb-a276-897505c07297/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:53,747 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bdf465f1-10a9-439c-b7d9-c4d2c30a2032 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:54,159 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/04333b76-4059-41a4-9a6f-59eb8fd741ee \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:54,606 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7cd8e685-deea-4afb-9b59-e78f9348fc09 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:55,890 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id b9043b1b-2eea-4bf9-a317-f3eeb3ae8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:09:57,187 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:57,266 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b9043b1b-2eea-4bf9-a317-f3eeb3ae8758 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:58,136 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bdf465f1-10a9-439c-b7d9-c4d2c30a2032 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:58,753 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/04333b76-4059-41a4-9a6f-59eb8fd741ee \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:59,777 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b9043b1b-2eea-4bf9-a317-f3eeb3ae8758 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:09:59,981 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7cd8e685-deea-4afb-9b59-e78f9348fc09 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:02,643 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:03,344 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b9043b1b-2eea-4bf9-a317-f3eeb3ae8758 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:03,622 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bdf465f1-10a9-439c-b7d9-c4d2c30a2032 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:04,098 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/04333b76-4059-41a4-9a6f-59eb8fd741ee \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:05,327 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7cd8e685-deea-4afb-9b59-e78f9348fc09 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:07,744 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b9043b1b-2eea-4bf9-a317-f3eeb3ae8758 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:08,147 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:09,088 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bdf465f1-10a9-439c-b7d9-c4d2c30a2032 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:09,712 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/04333b76-4059-41a4-9a6f-59eb8fd741ee \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:10,924 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7cd8e685-deea-4afb-9b59-e78f9348fc09 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:13,090 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b9043b1b-2eea-4bf9-a317-f3eeb3ae8758 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:14,251 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:15,167 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/04333b76-4059-41a4-9a6f-59eb8fd741ee \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:15,342 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bdf465f1-10a9-439c-b7d9-c4d2c30a2032 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:15,651 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/7cd8e685-deea-4afb-9b59-e78f9348fc09/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:15,854 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/bdf465f1-10a9-439c-b7d9-c4d2c30a2032/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:18,432 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b9043b1b-2eea-4bf9-a317-f3eeb3ae8758 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:19,703 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:20,677 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/04333b76-4059-41a4-9a6f-59eb8fd741ee \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:20,873 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 81ba3510-7473-4e7a-bdcd-e1e50fd7915f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:10:21,281 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/04333b76-4059-41a4-9a6f-59eb8fd741ee/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:22,233 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/81ba3510-7473-4e7a-bdcd-e1e50fd7915f \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:23,792 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b9043b1b-2eea-4bf9-a317-f3eeb3ae8758 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:24,583 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/81ba3510-7473-4e7a-bdcd-e1e50fd7915f \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:24,592 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 5c876ee7-df13-4f4b-8886-25ca5fbe7c7f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:10:25,070 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:26,197 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5c876ee7-df13-4f4b-8886-25ca5fbe7c7f \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:27,734 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:27,938 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/81ba3510-7473-4e7a-bdcd-e1e50fd7915f \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id d6e9af96-a1cb-4b3a-9463-011ad68ffffb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:10:28,496 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/81ba3510-7473-4e7a-bdcd-e1e50fd7915f/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:28,654 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5c876ee7-df13-4f4b-8886-25ca5fbe7c7f \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:29,167 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b9043b1b-2eea-4bf9-a317-f3eeb3ae8758 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:29,170 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d6e9af96-a1cb-4b3a-9463-011ad68ffffb \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:29,679 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/b9043b1b-2eea-4bf9-a317-f3eeb3ae8758/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:30,549 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:31,587 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d6e9af96-a1cb-4b3a-9463-011ad68ffffb \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:31,664 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id afc0a617-253a-4b11-a261-c332f647a668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:10:31,985 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:32,082 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d6e9af96-a1cb-4b3a-9463-011ad68ffffb/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id d9f1a998-33b7-44a4-844c-e018120195fd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:10:32,582 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5c876ee7-df13-4f4b-8886-25ca5fbe7c7f \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:33,182 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/afc0a617-253a-4b11-a261-c332f647a668 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:33,324 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d9f1a998-33b7-44a4-844c-e018120195fd \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:33,348 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5c876ee7-df13-4f4b-8886-25ca5fbe7c7f/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:33,476 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id d18387c8-0704-4a35-8236-9cd2763ee184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:10:34,723 - INFO - HTTP Request: POST https://api.cloud.llamaindex.ai/api/parsing/upload \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:34,826 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d18387c8-0704-4a35-8236-9cd2763ee184 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 5fae8a8b-cdd3-46e6-9471-7ed5eec60558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:10:35,618 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/afc0a617-253a-4b11-a261-c332f647a668 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:35,729 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d9f1a998-33b7-44a4-844c-e018120195fd \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:35,889 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:10:36,129 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5fae8a8b-cdd3-46e6-9471-7ed5eec60558 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:36,213 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/afc0a617-253a-4b11-a261-c332f647a668/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:37,257 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d18387c8-0704-4a35-8236-9cd2763ee184 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:38,529 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5fae8a8b-cdd3-46e6-9471-7ed5eec60558 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:40,658 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d18387c8-0704-4a35-8236-9cd2763ee184 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:41,352 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:42,889 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d9f1a998-33b7-44a4-844c-e018120195fd \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:43,195 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5fae8a8b-cdd3-46e6-9471-7ed5eec60558 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:43,811 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/5fae8a8b-cdd3-46e6-9471-7ed5eec60558/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:45,142 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d18387c8-0704-4a35-8236-9cd2763ee184 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:46,780 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:47,293 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d9f1a998-33b7-44a4-844c-e018120195fd \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:51,593 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d18387c8-0704-4a35-8236-9cd2763ee184 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:53,139 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d18387c8-0704-4a35-8236-9cd2763ee184/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:53,949 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:54,318 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d9f1a998-33b7-44a4-844c-e018120195fd \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:10:59,291 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:11:01,528 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d9f1a998-33b7-44a4-844c-e018120195fd \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:11:02,551 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/d9f1a998-33b7-44a4-844c-e018120195fd/result/markdown \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:11:04,630 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:11:10,599 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:11:16,991 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:11:22,944 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:11:29,186 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:11:35,628 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:11:41,585 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:11:47,704 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:11:53,959 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:12:04,243 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:12:10,326 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:12:16,283 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:12:23,451 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:12:29,596 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:12:35,939 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:12:42,089 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:12:48,233 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:12:54,242 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:13:00,318 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:13:06,666 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:13:12,748 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:13:18,822 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:13:24,784 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:13:30,937 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:13:37,384 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:13:43,430 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:13:49,574 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:13:56,147 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:14:02,134 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980 \"HTTP/1.1 200 OK\"\n",
      "2025-10-30 11:14:06,527 - INFO - HTTP Request: GET https://api.cloud.llamaindex.ai/api/parsing/job/3d6cf921-db75-4946-bc6a-4f19bd122980/result/markdown \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 887 nodes\n",
      "Sample: \n",
      "# Form 1040  \n",
      "## U.S. Individual Income Tax Return 2016  \n",
      "Department of the Treasury—Internal Revenue Service  \n",
      "OMB No. 1545-0074  \n",
      "IRS Use Only—Do not write or staple in this space.  \n",
      "\n",
      "For the year Jan. 1–Dec. 31, 2016, or other tax year beginning ________, 2016, ending ________, 20__  \n",
      "See separate instructions.  \n",
      "\n",
      "----\n",
      "\n",
      "### Your first name and initial  \n",
      "Henrietta  \n",
      "\n",
      "### Last name  \n",
      "Homeowner  \n"
     ]
    }
   ],
   "source": [
    "lp = LlamaParse(\n",
    "    parse_mode=\"parse_page_with_agent\",\n",
    "    model=\"openai-gpt-4-1-mini\",\n",
    "    high_res_ocr=True,\n",
    "    adaptive_long_table=True,\n",
    "    outlined_table_extraction=True,\n",
    "    output_tables_as_HTML=True,\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "patterns = [\"*.pdf\",\"*.docx\",\"*.doc\",\"*.xlsx\",\"*.xls\",\"*.pptx\",\"*.jpg\",\"*.jpeg\",\"*.png\",\"*.html\"]\n",
    "paths = []\n",
    "for pat in patterns:\n",
    "    paths.extend(glob.glob(os.path.join(\"train\", \"**\", pat), recursive=True))\n",
    "\n",
    "# Limit concurrency a bit to be polite and stable\n",
    "sema = asyncio.Semaphore(5)\n",
    "\n",
    "async def parse_one(path):\n",
    "    async with sema:\n",
    "        return await lp.aload_data(path)\n",
    "\n",
    "results = await asyncio.gather(*(parse_one(p) for p in paths))\n",
    "documents = [d for docs in results for d in docs]\n",
    "\n",
    "print(f\"Parsed {len(documents)} nodes\")\n",
    "print(\"Sample:\", documents[0].text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21393cb9-94b9-409b-bb23-bcc427bef8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample2: \n",
      "# DANI MARTINEZ  \n",
      "## COPYWRITING\n",
      "\n",
      "Id card  : 123-456-7890  \n",
      "Email    : hello@reallygreatsite.com  \n",
      "Address  : 123 Anywhere St., Any City  \n",
      "Phone    : 123-456-7890  \n",
      "\n",
      "www.reallygreatsite.com\n",
      "\n",
      "Studio Shodwe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample2:\", documents[-1].text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c40ec65-2756-4519-bfb5-2bb34d8465d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "887 {'source_path': 'train/blob_scanned_id_pay_return.pdf', 'file_name': 'blob_scanned_id_pay_return.pdf', 'source_type': 'pdf', 'split': 'train', 'page_index': 0, 'parser': 'LlamaParse', 'parse_mode': 'parse_page_with_agent', 'model': 'openai-gpt-4-1-mini', 'high_res_ocr': True, 'adaptive_long_table': True, 'outlined_table_extraction': True, 'output_tables_as_HTML': True, 'result_type': 'markdown'}\n"
     ]
    }
   ],
   "source": [
    "def ext_to_source_type(ext: str) -> str:\n",
    "    e = ext.lower()\n",
    "    if e in {\".pdf\"}: return \"pdf\"\n",
    "    if e in {\".docx\", \".doc\"}: return \"docx\"\n",
    "    if e in {\".xlsx\", \".xls\"}: return \"xlsx\"\n",
    "    if e in {\".jpg\", \".jpeg\", \".png\", \".tiff\", \".tif\"}: return \"image\"\n",
    "    if e in {\".pptx\"}: return \"pptx\"\n",
    "    if e in {\".html\", \".htm\"}: return \"html\"\n",
    "    return \"other\"\n",
    "    \n",
    "PARSE_CONFIG = {\n",
    "    \"parser\": \"LlamaParse\",\n",
    "    \"parse_mode\": \"parse_page_with_agent\",\n",
    "    \"model\": \"openai-gpt-4-1-mini\",\n",
    "    \"high_res_ocr\": True,\n",
    "    \"adaptive_long_table\": True,\n",
    "    \"outlined_table_extraction\": True,\n",
    "    \"output_tables_as_HTML\": True,\n",
    "    \"result_type\": \"markdown\",\n",
    "}\n",
    "\n",
    "documents_with_meta = []\n",
    "by_source = {}\n",
    "\n",
    "for path, docs in zip(paths, results):\n",
    "    file_name = os.path.basename(path)\n",
    "    source_type = ext_to_source_type(os.path.splitext(file_name)[1])\n",
    "\n",
    "    # store grouping for later logical-doc work\n",
    "    by_source[path] = docs\n",
    "\n",
    "    for page_idx, d in enumerate(docs):\n",
    "        md = d.metadata or {}\n",
    "        md.update({\n",
    "            \"source_path\": path,\n",
    "            \"file_name\": file_name,\n",
    "            \"source_type\": source_type,\n",
    "            \"page_index\": page_idx,\n",
    "            **PARSE_CONFIG,\n",
    "        })\n",
    "        d.metadata = md\n",
    "        documents_with_meta.append(d)\n",
    "\n",
    "# Replace your flat list if you want\n",
    "documents = documents_with_meta\n",
    "\n",
    "print(len(documents), documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbace48f-9952-4ece-a761-f12c73c49398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('documents_train.pkl', 'wb') as file:\n",
    "    pickle.dump(documents, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dab1aab4-b401-41d4-95c9-cc90cbbf840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_agent_text(response):\n",
    "    out = response.get(\"output\") or []\n",
    "    if isinstance(out, list) and out and isinstance(out[0], dict):\n",
    "        txt = out[0].get(\"text\")\n",
    "        if isinstance(txt, str):\n",
    "            return txt.strip()\n",
    "    return str(response)\n",
    "\n",
    "def rag_doctype_classifier(agent_id = '7c8cb2ad-7b1b-4396-892c-17a01807cf0b', input_text = None, stream = False, timeout = 20):\n",
    "    url = \"https://api.you.com/v1/agents/runs\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {you_key}\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"agent\": agent_id,\n",
    "        \"input\": input_text,\n",
    "        \"stream\": stream\n",
    "    }\n",
    "    resp = requests.post(url, json=payload, headers=headers, timeout=timeout)\n",
    "    resp.raise_for_status()\n",
    "    return extract_agent_text(resp.json())\n",
    "\n",
    "def rag_page_continue(agent_id = 'c3123621-1eb5-478d-a671-52ab0980c9e7', input_text = None, stream = False, timeout = 20):\n",
    "    url = \"https://api.you.com/v1/agents/runs\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {you_key}\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"agent\": agent_id,\n",
    "        \"input\": input_text,\n",
    "        \"stream\": stream\n",
    "    }\n",
    "    resp = requests.post(url, json=payload, headers=headers, timeout=timeout)\n",
    "    resp.raise_for_status()\n",
    "    return extract_agent_text(resp.json())\n",
    "\n",
    "def rag_query_router(agent_id = 'b2c1b36e-4da0-481f-a5ef-931b5cf60a1c', input_text = None, stream = False, timeout = 20):\n",
    "    url = \"https://api.you.com/v1/agents/runs\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {you_key}\",\n",
    "    }\n",
    "    payload = {\n",
    "        \"agent\": agent_id,\n",
    "        \"input\": input_text,\n",
    "        \"stream\": stream\n",
    "    }\n",
    "    resp = requests.post(url, json=payload, headers=headers, timeout=timeout)\n",
    "    resp.raise_for_status()\n",
    "    return extract_agent_text(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "db23a4f9-7c71-4b13-a800-696a885e96da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Other'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_query_router(input_text= \"how to make a cake?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1c88ab33-9972-4af1-ad9e-98d3d4118fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ID'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_doctype_classifier(input_text=documents[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95f03d42-03ba-4a39-97d4-efa23f79ce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# KANSAS DRIVER\\'S LICENSE\\n\\n**USA KS**\\n\\n| Field          | Information           |\\n|----------------|-----------------------|\\n| LIC. NO.       | K12-34-5678           |\\n| DOB            | 01/11/1966            |\\n| ISS            | 01/11/2017            |\\n| EXP            | 01/11/2023            |\\n| Name           | SAMPLE                |\\n|                | CARON ELIZABETH       |\\n| Address        | 123 NORTH STREET      |\\n|                | APT. 2                |\\n|                | TOPEKA, KS 66612-1234 |\\n| CLASS          | A                     |\\n| END            | NONE                  |\\n| SEX            | F                     |\\n| REST           | NONE                  |\\n| HGT            | 5\\'-06\"                |\\n| WGT            | 140 lb                |\\n| EYES           | BRO                   |\\n| DD             | XX123XWMXX1           |\\n| DONOR          | [x] DONOR             |\\n| Additional DD  | 23XWMX123XWM12        |\\n\\n**Signature:**  \\n`Caron Sample`\\n\\n\\n'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2ad1f332-8bc0-43f8-8dce-92baae046935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Documents Processed\n",
      "200 Documents Processed\n",
      "300 Documents Processed\n",
      "400 Documents Processed\n",
      "500 Documents Processed\n",
      "600 Documents Processed\n",
      "700 Documents Processed\n",
      "800 Documents Processed\n"
     ]
    }
   ],
   "source": [
    "#logical document creation\n",
    "\n",
    "metadata = []\n",
    "current_doc_type = None\n",
    "page_in_doc = 0\n",
    "is_new_doc = True\n",
    "logical_documents = []\n",
    "\n",
    "for i, page in enumerate(documents):\n",
    "    if i == 0:\n",
    "        current_doc_type = rag_doctype_classifier(input_text = page.text)\n",
    "        text = page.text\n",
    "    else:\n",
    "        prev_text = documents[i - 1].text\n",
    "        \n",
    "        output = rag_page_continue(input_text= f\"\"\"\n",
    "        Page 1: {prev_text[:4000]}\n",
    "        Doctype Page 1: {current_doc_type}\n",
    "        Page 2: {page.text[:4000]}\"\"\")\n",
    "        \n",
    "        if output.startswith('y'):\n",
    "            current_doc_type = rag_doctype_classifier(input_text = page.text)\n",
    "            page_in_doc = 0\n",
    "            text = page.text\n",
    "            is_new_doc = True\n",
    "            \n",
    "        else:\n",
    "            page_in_doc += 1\n",
    "            text = text + \"\\n\\n\" + page.text\n",
    "            is_new_doc = False\n",
    "    if ((i+1) % 100) == 0:\n",
    "        print(f'{i+1} Documents Processed')\n",
    "    metadata.append({\n",
    "        \"page\": i,\n",
    "        'is_new_doc': is_new_doc,\n",
    "        \"doc_type\": current_doc_type,\n",
    "        'page_in_doc': page_in_doc,\n",
    "        'file_name': page.metadata['file_name'],\n",
    "    })\n",
    "\n",
    "    if is_new_doc:\n",
    "        logical_documents.append({\n",
    "            'text': text,\n",
    "            'doc_type': current_doc_type,\n",
    "            'page_start': i,\n",
    "            'page_end': i\n",
    "        })\n",
    "    else:\n",
    "        logical_documents[-1]['page_end'] = i\n",
    "        logical_documents[-1]['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4e6a1c0d-9c5f-40bd-8f8e-a18c4591226d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page': 0,\n",
       "  'is_new_doc': True,\n",
       "  'doc_type': 'TaxDocument',\n",
       "  'page_in_doc': 0,\n",
       "  'file_name': 'blob_scanned_id_pay_return.pdf'},\n",
       " {'page': 1,\n",
       "  'is_new_doc': False,\n",
       "  'doc_type': 'TaxDocument',\n",
       "  'page_in_doc': 1,\n",
       "  'file_name': 'blob_scanned_id_pay_return.pdf'}]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "af15febe-4812-426a-8e77-aea24acb7f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Logical Documents:  630\n"
     ]
    }
   ],
   "source": [
    "with open('metadata_train.pkl', 'wb') as file:\n",
    "    pickle.dump(metadata, file)\n",
    "\n",
    "with open('logical_train.pkl', 'wb') as file:\n",
    "    pickle.dump(logical_documents, file)\n",
    "\n",
    "print('Number of Logical Documents: ', len(logical_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8a07fa-205e-40c5-98dc-db7eed470893",
   "metadata": {},
   "source": [
    "## RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9a55c2c8-7cc9-41f4-b242-5523e356cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16361/2000535101.py:6: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
      "  llm = Gemini(\n",
      "2025-10-30 23:57:16,316 - INFO - Load pretrained SentenceTransformer: BAAI/bge-large-en-v1.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1413506c870d4a88a6e4e5592a579628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e716f2ed05649e98f63d3108c7d8a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fafe917a97b4c698d17b55d6672d5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235930ff8bce4f3da782c51d751ac951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb33bc201b745239422004a311875d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a708c48cb2e5402c9ce2abd752f0ea2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83952d9ec75c4059a881f351192225e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d553fc9910d45278593d6e8976176ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84911ead75354ff88a348a8d3aea6e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7d136a898045a3a58e3071236c9ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a356acd88742339c91adcaff348cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 23:58:07,363 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Settings, Document, VectorStoreIndex\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# LLM: Gemini for RAG generation\n",
    "llm = Gemini(\n",
    "    model = os.getenv(\"GEMINI_MODEL\", \"gemini-2.5-flash\"),\n",
    "    api_key = gemini_key,\n",
    "    temperature = 0.1,\n",
    "    max_tokens = 512,\n",
    ")\n",
    "Settings.llm = llm\n",
    "\n",
    "embed = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "Settings.embed_model = embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3a36fb65-5201-4bbd-abc8-aecaca0f69bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursive chunking\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1600, chunk_overlap = 150)\n",
    "\n",
    "chunked_documents = []\n",
    "\n",
    "for idx, doc in enumerate(logical_documents):\n",
    "    chunks = splitter.split_text(doc[\"text\"])\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        chunked_documents.append(\n",
    "            Document(\n",
    "                text=chunk,\n",
    "                metadata={\n",
    "                    \"doc_type\": doc[\"doc_type\"],\n",
    "                    \"chunk_index\": chunk_idx,\n",
    "                    \"page_start\": doc[\"page_start\"],\n",
    "                    \"page_end\": doc[\"page_end\"],\n",
    "                }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4161f2bc-8fa5-47ca-9cec-99f87160f7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef5f26-0210-4454-9117-bc53a7e18ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0444b073-c788-4e01-a5cd-2642dabd514a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_type': 'FinancialModel',\n",
       " 'chunk_index': 34,\n",
       " 'page_start': 878,\n",
       " 'page_end': 886}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_documents[-1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "66a371a6-0a44-40b8-965c-75c5913e233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#semantic chunking\n",
    "\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "\n",
    "semantic_splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size = 15,                      # keeps neighboring sentences in context when deciding\n",
    "    breakpoint_percentile_threshold = 90,  # higher = fewer, stronger splits\n",
    "    embed_model = Settings.embed_model\n",
    ")\n",
    "\n",
    "# Convert coarse nodes back to Documents for the semantic splitter\n",
    "semantic_chunks = semantic_splitter.get_nodes_from_documents(chunked_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "db15ca62-3a3d-4a20-b8b9-1ce648451b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558\n"
     ]
    }
   ],
   "source": [
    "print(len(semantic_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ef4e6aed-6073-46d8-92b3-91863a9552ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_type': 'FinancialModel',\n",
       " 'chunk_index': 34,\n",
       " 'page_start': 878,\n",
       " 'page_end': 886}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_chunks[-1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6782c918-8d43-4196-80a6-d0363d1fddfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 00:35:41,581 - INFO - Loading faiss with AVX512 support.\n",
      "2025-10-31 00:35:41,649 - INFO - Successfully loaded faiss with AVX512 support.\n"
     ]
    }
   ],
   "source": [
    "#scalable faiss store\n",
    "\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "probe = Settings.embed_model.get_text_embedding(\"dimension probe\")\n",
    "dim = len(probe)\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(dim)\n",
    "vector_store = FaissVectorStore(faiss_index = faiss_index) \n",
    "\n",
    "#Build a VectorStoreIndex over semantic chunks\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
    "index = VectorStoreIndex(semantic_chunks, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b8d39abb-7741-4e9d-bd5c-1cc21847b488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9eb52891-9e9b-4b56-9396-125b4134ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading additonal libraries\n",
    "from llama_index.core import Settings, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever, QueryFusionRetriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine, SubQuestionQueryEngine\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.postprocessor.types import BaseNodePostprocessor\n",
    "from collections import defaultdict\n",
    "from llama_index.core.question_gen import LLMQuestionGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "826ede1e-fdce-4198-9b09-c4f23f84592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1c778562-aac5-460b-abbe-bae11f5ca26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 11:34:26,334 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,415 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,421 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,431 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,503 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,622 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,665 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,707 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,724 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,740 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,752 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,757 - DEBUG - Building index from IDs objects\n",
      "2025-10-31 11:34:26,759 - WARNING - As bm25s.BM25 requires k less than or equal to number of nodes added. Overriding the value of similarity_top_k to number of nodes added.\n",
      "2025-10-31 11:34:26,779 - DEBUG - Building index from IDs objects\n"
     ]
    }
   ],
   "source": [
    "all_nodes = list(index.docstore.docs.values()) \n",
    "\n",
    "#BM25 retriever\n",
    "bm25_all = BM25Retriever.from_defaults(nodes=all_nodes, similarity_top_k=12) \n",
    "\n",
    "class SoftDocTypeFilterPostprocessor(BaseNodePostprocessor):\n",
    "    doc_type: Optional[str] = None\n",
    "    keep_top_n: int = 8\n",
    "    min_filtered: int = 2\n",
    "\n",
    "    def _postprocess_nodes(self, nodes, query_bundle=None):\n",
    "        if not nodes or not self.doc_type:\n",
    "            return nodes[: self.keep_top_n]\n",
    "\n",
    "        # preserve fused order\n",
    "        filtered = [n for n in nodes if (n.node.metadata or {}).get(\"doc_type\") == self.doc_type]\n",
    "        if len(filtered) >= self.min_filtered:\n",
    "            return filtered[: self.keep_top_n]\n",
    "\n",
    "        # Not enough filtered hits -> mix: filtered first, then best off-doctype to fill\n",
    "        taken_ids = {n.node.node_id for n in filtered}\n",
    "        mixed = list(filtered)\n",
    "        for n in nodes:\n",
    "            if n.node.node_id in taken_ids:\n",
    "                continue\n",
    "            mixed.append(n)\n",
    "            if len(mixed) >= self.keep_top_n:\n",
    "                break\n",
    "        return mixed\n",
    "\n",
    "\n",
    "nodes_by_dt = defaultdict(list)\n",
    "for n in all_nodes:\n",
    "    dt = (n.metadata or {}).get(\"doc_type\", \"Unknown\")\n",
    "    nodes_by_dt[dt].append(n)\n",
    "\n",
    "bm25_by_dt = {\n",
    "    dt: BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=12)\n",
    "    for dt, nodes in nodes_by_dt.items() if nodes\n",
    "}\n",
    "\n",
    "#  (vector + BM25 + filter + reranker)\n",
    "def make_engine_for_doctype(predicted_doc_type=None, k_per=12, final_top_n=5):\n",
    "    \n",
    "    vec = index.as_retriever(similarity_top_k=k_per)\n",
    "\n",
    "    bm25 = bm25_by_dt.get(predicted_doc_type, bm25_all)\n",
    "\n",
    "    bm25 = bm25_by_dt.get(predicted_doc_type, bm25_all)\n",
    "    if predicted_doc_type in nodes_by_dt and len(nodes_by_dt[predicted_doc_type]) < 100:\n",
    "        bm25 = bm25_all\n",
    "\n",
    "    # Fuse vector + BM25; set small num_queries for light LLM expansion\n",
    "    fusion = QueryFusionRetriever(\n",
    "        retrievers = [vec, bm25],\n",
    "        llm = Settings.llm,\n",
    "        similarity_top_k = k_per,\n",
    "        num_queries = 2,             \n",
    "        mode = \"reciprocal_rerank\",\n",
    "    )\n",
    "\n",
    "    reranker = SentenceTransformerRerank(\n",
    "        model = \"cross-encoder/ms-marco-MiniLM-L-2-v2\",\n",
    "        top_n = final_top_n,\n",
    "    )\n",
    "\n",
    "    post = []\n",
    "    if predicted_doc_type and predicted_doc_type.lower() != \"other\":\n",
    "        post.append(SoftDocTypeFilterPostprocessor(\n",
    "            doc_type = predicted_doc_type,\n",
    "            keep_top_n = final_top_n,\n",
    "            min_filtered = 2,\n",
    "        ))\n",
    "    post.append(reranker)\n",
    "\n",
    "\n",
    "    resp_synth = get_response_synthesizer(response_mode = \"compact\")\n",
    "\n",
    "    return RetrieverQueryEngine.from_args(\n",
    "        retriever = fusion,\n",
    "        llm = Settings.llm,\n",
    "        response_synthesizer = resp_synth,\n",
    "        node_postprocessors = post,\n",
    "        verbose = False,\n",
    "    )\n",
    "\n",
    "def get_engine_for_query(query):\n",
    "    label = rag_query_router(input_text=query)\n",
    "    predicted_doc_type = None\n",
    "    if label and label.strip().lower() != \"other\":\n",
    "        predicted_doc_type = label.strip()\n",
    "    return make_engine_for_doctype(predicted_doc_type=predicted_doc_type)\n",
    "\n",
    "tools = []\n",
    "seen = set((n.metadata or {}).get(\"doc_type\", \"Unknown\") for n in all_nodes)\n",
    "for dt in sorted(seen):\n",
    "    if not dt or dt.lower() == \"unknown\":\n",
    "        continue\n",
    "    qe_dt = make_engine_for_doctype(predicted_doc_type=dt)\n",
    "    tools.append(\n",
    "        QueryEngineTool(\n",
    "            query_engine=qe_dt,\n",
    "            metadata=ToolMetadata(\n",
    "                name=f\"engine_{dt}\",\n",
    "                description=f\"Answer questions about {dt} documents\",\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Global fallback tool (no doctype restriction)\n",
    "qe_global = make_engine_for_doctype(predicted_doc_type=None)\n",
    "tools.append(\n",
    "    QueryEngineTool(\n",
    "        query_engine=qe_global,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"engine_global\",\n",
    "            description=\"Use when the doctype is unclear or when doctype-specific context seems missing which happens when metadata tagging is wrong.\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "#main engine\n",
    "question_gen = LLMQuestionGenerator.from_defaults(llm = Settings.llm)\n",
    "qe_main = SubQuestionQueryEngine.from_defaults(\n",
    "    query_engine_tools = tools,\n",
    "    question_gen = question_gen,\n",
    "    llm = Settings.llm,\n",
    "    verbose = False,\n",
    "    use_async = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9175a7d-8f25-490f-a153-be05f690ad92",
   "metadata": {},
   "source": [
    "## Query Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d4b93-b0d4-4ef9-beab-e49ae864dbf7",
   "metadata": {},
   "source": [
    "In this part we will test 15 queries we made before training this pipeline. It is a range of queries mirroring the needs of finance/legal professionals in their day to day tasks as it cover field extraction, summarization, and complex questions centered around legal documents and excel workings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c4786be3-41de-45ef-a11a-3beb154573ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabf261df8394a51b402cb06eaf53c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closing balance for John Doe's bank statement is 17.03.\n"
     ]
    }
   ],
   "source": [
    "#test query\n",
    "response = qe_main.query(\"What is the closing balance for John Doe's Bank Statement?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "cf04b3f4-8eac-4a7e-a99c-65a653ed6c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fdd9ffd2964eafb2b423034da51665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7305ef72e4497a8f0074a99a7a970c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4892ec9426cf44cfa4ad10f2b763f184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b47b2b65c7a4d04affea8ecfa452dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "The main numerical figures in the ACC Limited revenue model are:\n",
      "\n",
      "*   **Cement Sales - Value in cr:**\n",
      "    *   2015: 11,917\n",
      "    *   2016: 11,112\n",
      "    *   2017: 13,414\n",
      "    *   2018 F: 14,441\n",
      "    *   2019 F: 15,537\n",
      "    *   2020 F: 16,707\n",
      "    *   2021 F: 17,955\n",
      "    *   2022 F: 19,287\n",
      "*   **Cement Sales - Volume Million Tonnes:**\n",
      "    *   2015: 23.62\n",
      "    *   2016: 22.99\n",
      "    *   2017: 26.21\n",
      "    *   2018 F: 26.87\n",
      "    *   2019 F: 27.54\n",
      "    *   2020 F: 28.20\n",
      "    *   2021 F: 28.86\n",
      "    *   2022 F: 29.53\n",
      "*   **Average price in crores per Million Tonnes:**\n",
      "    *   2015: 505\n",
      "    *   2016: 483\n",
      "    *   2017: 512\n",
      "    *   2018 F: 537\n",
      "    *   2019 F: 564\n",
      "    *   2020 F: 592\n",
      "    *   2021 F: 622\n",
      "    *   2022 F: 653\n",
      "*   **Average price per tonne:**\n",
      "    *   2015: 5,045\n",
      "    *   2016: 4,833\n",
      "    *   2017: 5,118\n",
      "    *   2018 F: 5,374\n",
      "    *   2019 F: 5,642\n",
      "    *   2020 F: 5,924\n",
      "    *   2021 F: 6,221\n",
      "    *   2022 F: 6,532\n",
      "*   **Average price per kg:**\n",
      "    *   2015: 5.0\n",
      "    *   2016: 4.8\n",
      "    *   2017: 5.1\n",
      "    *   2018 F: 5.4\n",
      "    *   2019 F: 5.6\n",
      "    *   2020 F: 5.9\n",
      "    *   2021 F: 6.2\n",
      "    *   2022 F: 6.5\n",
      "\n",
      "Information regarding the main numerical figures in the ACC Limited revenue model workings is not available.\n",
      "\n",
      "The top 5 most important figures from the ACC Ltd revenue model are:\n",
      "\n",
      "*   Cement Sales - Value in cr\n",
      "*   Cement Sales - Volume Million Tonnes\n",
      "*   Average price in crores per Million Tonnes\n",
      "*   Capacity Million Tonnes\n",
      "*   Capacity utilisation\n",
      "\n",
      "The top 5 most important figures from the ACC Limited revenue model workings are not available.\n",
      "\n",
      "Query execution time: 43.139 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"What are the main numerical figures I should know in the ACC Limited revenue model and its workings? And Extract top 5 most important figures.\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "raw = str(response)\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(raw)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292acf4-5565-406b-b2eb-e4df68300162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "599f3f2d-e728-4623-a4bf-4cf1cedf5a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a47fad04304b31b3fd77732b9e3842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "Here are the driver's license details for Caron Elizabeth:\n",
      "\n",
      "*   **License Number:** K12-34-5678\n",
      "*   **Date of Birth (DOB):** 01/11/1966\n",
      "*   **Issue Date (ISS):** 01/11/2017\n",
      "*   **Expiration Date (EXP):** 01/11/2023\n",
      "*   **Name:** SAMPLE CARON ELIZABETH\n",
      "*   **Address:** 123 NORTH STREET, APT. 2, TOPEKA, KS 66612-1234\n",
      "*   **Class:** A\n",
      "*   **Endorsements (END):** NONE\n",
      "*   **Sex:** F\n",
      "*   **Restrictions (REST):** NONE\n",
      "*   **Height (HGT):** 5'-06\"\n",
      "*   **Weight (WGT):** 140 lb\n",
      "*   **Eyes:** BRO\n",
      "*   **DD:** XX123XWMXX1\n",
      "*   **Donor Status:** DONOR\n",
      "*   **Additional DD:** 23XWMX123XWM12\n",
      "\n",
      "Query execution time: 17.792 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"Extract driver licence details for Caron Elizabeth\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ad7c7630-0b9a-42fb-a7ae-bd5f0040bf4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb2981be41541e986e60182b0f87556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "The revenue fields in the income statement for XYZ Limited are:\n",
      "*   Fair value of milk produced\n",
      "*   Gains arising from changes in fair value less estimated point-of-sale costs of dairy livestock\n",
      "*   Total Income\n",
      "\n",
      "Query execution time: 15.610 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test, this time for a query not solved by RAG properly\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"Extract revenue fields in the income statement for XYZ Limited.\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e6be6d5d-ea9e-4421-b3a4-9e3f1e1af7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f54882d54f4dd98a235d934f7bef9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "In March 2022, the top revenue fields for Interglobe Aviation and their values were:\n",
      "\n",
      "*   **Passenger ticket revenue:** 450,243 Million INR\n",
      "*   **Ancillary Revenue:** 56,280 Million INR\n",
      "\n",
      "Query execution time: 17.992 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test, this time for a query not solved by RAG properly\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"What are the top revenue fields and their values in March 2022 for the Interglobe Aviation as per the Revenue/Financial Model?\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "66525653-9b17-458c-be27-fb54d401e7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cac3e6992cb4e2eb55db3717358a963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23869913a6164ce58cd02fa68d039b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "The total estimated monthly payment for the property mortgage is $2,308.95. This payment is comprised of the following key components:\n",
      "\n",
      "*   Principal and interest: $1,869.37\n",
      "*   Hazard insurance: $39.58\n",
      "*   Real estate taxes: $400.00\n",
      "\n",
      "Query execution time: 28.408 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"What is the total estimated monthly payment for the property mortgage as per lender fees worksheet? Break down its key compnents too.\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "468ef77d-b3ae-4dbf-820b-0be60f92b6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31403744412d4d7e809c7c5eff414eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "NVIDIA reported second-quarter revenue of $601 million, an 18% increase from the prior quarter and a 32% rise compared to the same period last year. Automotive revenue specifically reached $586 million, showing a 3% sequential increase and a 69% year-over-year growth. The company's net income for the quarter was $25,783 million, resulting in diluted earnings per share of $1.05. When excluding H20 related charges/releases, net, and their associated tax impact, diluted earnings per share stood at $1.04.\n",
      "\n",
      "Query execution time: 10.297 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"Summarize Nvidia's financial results for second quarter of 2026.\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f91311f8-d3f4-426a-990c-aecd74932397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6a4b7e1f0f4541a862a760254ef65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "ISA 220 (Revised), *Quality Management for an Audit of Financial Statements*, outlines the specific responsibilities of the auditor regarding quality management at the engagement level for an audit of financial statements. It also addresses the related responsibilities of the engagement partner. Furthermore, this standard covers the auditor’s responsibilities concerning relevant ethical requirements, including those pertaining to independence, specifically within the context of accepting an audit engagement and for matters under the auditor's control.\n",
      "\n",
      "Query execution time: 11.595 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"What are the scope and requirements of ISA 220 Quality Management?\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "e2db59d8-a113-4360-acb4-22b37d1d91e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739a2147df2a460d8fb4dc884a563887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209c00bcecec4679b63483bb93db3fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "James Bond's total earnings are 8800, which comprises a Basic Pay of 8000, an Allowance of 500, and Overtime of 300. His Net Pay is 8000.\n",
      "\n",
      "Query execution time: 24.044 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"What are the earnings and Net Pay of James Bond as per his payslip?\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "240761c2-aa1e-41b7-93e7-992b92e20462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fafc0197b442a0bc921ac9c2ea1c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "The supply of services is governed by the Terms and Conditions outlined in the official Purchase Order issued by the Great Ocean Road Coast and Parks Authority, which also details the applicable General Conditions.\n",
      "\n",
      "Regarding the performance of these services, the provider is responsible for supplying all necessary equipment. If the services are not delivered in accordance with the agreement, the Authority is not obligated to make payment until the services are correctly rendered. In such instances, the Authority may require the supplier to remedy any default or re-perform the services within a reasonable period. Should the default be irremediable, the services cannot be re-performed, or if the supplier fails to act within the specified timeframe, the Authority reserves the right to arrange for a third party to remedy or re-perform the services, or to undertake the task itself. In these situations, the supplier will be held responsible for any reasonable costs incurred.\n",
      "\n",
      "Query execution time: 17.000 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"What are the conditions for supply of services as per Purchase Order Agreement of Great Ocean Road?\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "f82bea24-4450-45be-aeed-f7021d0d0064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3d8f3a966d4bfa8decdb88809ac537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "The Contractor assures Mercy Corps that it has the complete rights and authority to enter into and perform its contractual obligations, and that its performance will not violate any agreements with third parties. Furthermore, the Contractor guarantees that it possesses the required skills to execute the Services as specified in the Statement of Work.\n",
      "\n",
      "Query execution time: 9.280 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"Summarize  Representations, Warranties and Additional Covenants in contractor service contract for Mercy Corps.\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "9672b0dd-7c5f-41fb-b240-b9075468bf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4e59132b65444ca4d9f41ab0806241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "The total amount payable to CPB Software for invoices in 2024 is 251.12 €. This amount includes charges for user-account-1 totaling 154.30 € and user-account-2 totaling 96.82 € for the period 01.02.2024 to 29.02.2024.\n",
      "\n",
      "Query execution time: 21.806 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"What is the total amount payable to CPB Software as per invoices in 2024?\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "fd3c014e-14eb-4ca5-91b5-69a80c364800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325263dced8341f4995e5daa17bbcbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7a9143e7e74c469ebf1bfcfeb9331d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "A total of 49,117.5 units of the Amarilla product were sold in 2014.\n",
      "\n",
      "The breakdown of units sold per segment for the Amarilla product in 2014 is as follows:\n",
      "*   **Government:** 22,124 units\n",
      "*   **Small Business:** 4,467 units\n",
      "*   **Midmarket:** 1,326 units\n",
      "*   **Channel Partners:** 4,504 units\n",
      "*   **Enterprise:** 7,523.5 units\n",
      "\n",
      "Query execution time: 39.275 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"How many units were sold for Amarilla product in 2014? Give a total amount, and then break down the total amount into units sold per segment for Amarilla for the same period.\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "187d4881-a72d-4d9d-b2b1-69269937cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5647aad276846bd88bc11eb95dc97d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457bcfa8380148b7a3490ad8a2e1466b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "Article 7 establishes a limitation of personal liability for individuals associated with the Owner. It specifies that no director, employee, consultant, or agent of the Owner, or any person representing or acting on behalf of the Owner in connection with the contract, shall have any personal liability to the Contractor or any of its sub-contractors, agents, representatives, directors, or employees. Furthermore, the Contractor, on its own behalf and on behalf of its sub-contractors, directors, employees, agents, and representatives, waives and disclaims any and all rights of action it or they may have, whether under tort or contract or otherwise, against the Owner or any director, employee, agent, consultant, or representative of the Owner for any act of omission or commission done or omitted to be done.\n",
      "\n",
      "Article 8 clarifies that any failure or delay by the Owner in enforcing a right, remedy, obligation, or liability under the contract does not constitute a waiver of that right, remedy, obligation, or liability. The Owner retains the entitlement to enforce such provisions at any time, regardless of prior inaction or delay.\n",
      "\n",
      "Query execution time: 27.176 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"Explain Article 7 and 8 mentioned in the format of contract agreement.\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "923fdc5e-2ff4-4cde-bc2f-4a341a8b2f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67df498e510a424ab2cb4b041db2ecc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      " ---------------------- \n",
      "\n",
      "IAS 16, effective from January 1, 1995, provides guidance on Property, Plant and Equipment. It mandates that these assets should be recognized when it is probable that future economic benefits will flow from them and their cost can be reliably measured. Initial measurement of these assets is required to be at cost.\n",
      "\n",
      "The standard has undergone several amendments since its inception. It was amended by IAS 1 in July 1997, and further revised in April and July 1998 to ensure consistency with IAS 22, IAS 36, and IAS 37, with this revised version becoming operative for periods beginning on or after July 1, 1999. Its scope was also adjusted by IAS 40 in April 2000 and by IAS 41 in January 2001.\n",
      "\n",
      "Additionally, two SIC Interpretations are relevant to IAS 16: SIC 14, which addresses compensation for the impairment or loss of items, and SIC 23, concerning major inspection or overhaul costs. Entities applying the cost model for investment property under IAS 40 are required to furnish all the disclosure requirements specified by IAS 16.\n",
      "\n",
      "Query execution time: 13.898 seconds\n"
     ]
    }
   ],
   "source": [
    "#another test\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "query = \"Summarize the IAS 16.\"\n",
    "response = qe_main.query(query)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print('\\nFinal Response:\\n ---------------------- \\n')\n",
    "print(response)  \n",
    "print(f\"\\nQuery execution time: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "0e0111d0-fe91-4ebe-ab90-a05afc6e6eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method TextNode.get_content of TextNode(id_='db62d004-20d7-4214-8f7e-b51fba1dc4f8', embedding=None, metadata={'doc_type': 'EmployeeContract', 'chunk_index': 4, 'page_start': 8, 'page_end': 10}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f85a8d89-3f81-4ea1-af90-4be740fcc3ef', node_type='4', metadata={'doc_type': 'EmployeeContract', 'chunk_index': 4, 'page_start': 8, 'page_end': 10}, hash='6c7dbc45cbc60e00df04db2f788962bdbb791651b909f32a9dc6e2b514511cff')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='### ARTICLE 6. Appendices\\n\\nThe Appendices listed in the attached list of Appendices shall be deemed to form an integral part of this Contract  \\nAgreement.  \\nReference in the Contract to any Appendix shall mean the Appendices attached hereto, and the Contract shall be  \\nread and construed accordingly.\\n\\n### ARTICLE 7. NO LIABILITY ON DIRECTOR AND EMPLOYEE\\n\\nNo Director, employee, consultant or agent of the OWNER or other person representing the  \\nOWNER or acting on behalf of the OWNER in or pursuant to the Contract or in the discharge of any obligation to the  \\nOWNER under the Contract or otherwise in relation to the Contract shall have any personal liability to the  \\nCONTRACTOR or any Sub-Contractor, agent, representative, director or employee of the CONTRACTOR or to any  \\nother person acting for or on behalf of the CONTRACTOR and the CONTRACTOR on its own behalf and on behalf of  \\nits Sub Contractors, directors, employees, agents and representatives hereby waives and disclaims any and all right  \\nof action which it or they may have whether under tort or Contract or otherwise against the OWNER or any director,  \\nemployee, agent, consultant or  \\nrepresentative of the OWNER for act of omission or commission done or omitted to be done.\\n\\n### ARTICLE 8. WAIVER\\n\\nNo failure or delay by the OWNER in enforcing any right or remedy of the OWNER in terms of the CONTRACT or any  \\nobligation or liability of the CONTRACTOR in terms thereof, shall be deemed to be a waiver of such right, remedy,', mimetype='text/plain', start_char_idx=0, end_char_idx=1501, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_nodes)):\n",
    "    if 'ARTICLE 8' in all_nodes[i].text:\n",
    "        print(all_nodes[i].get_content)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee5469-7df4-48a1-9c94-357b6886bdca",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "8d08f829-c09e-405e-8978-bba9a2004840",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_ids_by_query = {\n",
    "    \"What is the closing balance for John Doe's Bank Statement?\": {\n",
    "        \"3c1f4f03-9757-493c-b0b8-c7d3650d6768\",\n",
    "    },\n",
    "    \"What are the main numerical figures I should know in the ACC Limited revenue model and its workings? And Extract top 5 most important figures.\": {\n",
    "        \"1f8dc041-1b55-4c40-bea2-170d7f9b97da\",\n",
    "    },\n",
    "    \"Extract driver licence details for Caron Elizabeth\": {\n",
    "        \"4889f6a7-7ada-41da-961d-d781d0cf4946\",\n",
    "    },\n",
    "    \"What are the scope and requirements of ISA 220 Quality Management?\": {\n",
    "        \"d09b3c01-33f9-4a7c-a08f-267d7282df47\",\n",
    "        \"1a620326-d1a3-45d8-aedf-919638fc88af\",\n",
    "        \"28b0ce01-6f42-4b5b-9939-ce8ff156b063\",\n",
    "    },\n",
    "    \"Extract revenue fields in the income statement for XYZ Limited.\": {\n",
    "        \"7966b441-d0d2-4198-a426-a18fc6ea90dc\",\n",
    "    },\n",
    "    \"What are the top revenue fields and their values in March 2022 for the Interglobe Aviation as per the Revenue/Financial Model?\": {\n",
    "        \"80002318-d430-43f7-94d3-6ef5140ba3a1\",\n",
    "    },\n",
    "    \"What is the total estimated monthly payment for the property mortgage as per lender fees worksheet? Break down its key compnents too.\": {\n",
    "        \"fe2db0d8-ec2e-457c-86c6-a3dfe278f317\",\n",
    "        \"4bf297dd-5c8b-4b51-bd48-e756809749c4\",\n",
    "    },\n",
    "    \"Summarize Nvidia's financial results for second quarter of 2026.\": {\n",
    "        \"472095f3-d185-495a-86f6-fd5ac7493f01\",\n",
    "        \"29e49d15-f434-4101-9c28-a2dd21d4a62d\",\n",
    "        \"edd15543-65f0-41a6-8663-35ac8338f255\",\n",
    "    },\n",
    "    \"What are the earnings and Net Pay of James Bond as per his payslip?\": {\n",
    "        \"83fd248a-3c02-4d20-a3c8-ed69db399c1d\",\n",
    "        \"dec5a78a-9f08-43a9-ac5d-ca02085ac040\",\n",
    "    },\n",
    "    \"What are conditions for supply of services as per PO Agreement of Great Ocean Road?\": {\n",
    "        \"cdec08c4-118f-47c7-815d-c5ec58dc4446\",\n",
    "        \"9223d137-7ad4-4373-aa2e-25b9dfeef6f9\",\n",
    "    },\n",
    "    \"Summarize  Representations, Warranties and Additional Covenants in contractor service contract for Mercy Corps.\": {\n",
    "        \"15edf483-c3d5-41be-83f2-047e99709169\",\n",
    "        \"7dd5bd88-5e70-4832-a645-42b14fff94bd\",\n",
    "        \"bb2c0831-8bd1-4aa0-9523-eca534d4983b\",\n",
    "    },\n",
    "    \"What is the total gross amount payable including taxes to CPB software as per invoices in 2024?\": {\n",
    "        \"9b2881ea-afb2-469a-ba81-40d2bba08e87\",\n",
    "        \"142acf58-50c5-4541-9e21-497f6567c557\",\n",
    "    },\n",
    "    \"Summarize the IAS 16.\": {\n",
    "        \"f75be588-6e68-4fb7-b979-d7b72ce1122c\",\n",
    "    },\n",
    "    \"How many units were sold for Amarilla product in 2014? Give a total amount, and then break down the amount into units sold per segment for Amarilla for the same period.\": {\n",
    "        \"1708a705-95ed-4350-a1dc-24f577d48a9d\",\n",
    "        \"3c202fc9-7d82-4449-a607-0c4cd27be31c\",\n",
    "        \"6afe17d4-79ee-4509-94bd-ba0ee7991178\",\n",
    "        \"5ba196d7-27a1-456a-b704-9f274b3721e9\",\n",
    "        \"e6f0f5e2-4214-4f4c-84b1-b53d1b0dfb4a\",\n",
    "        \"bcfc68ce-5482-4489-87c0-6a75f98073fc\",\n",
    "    },\n",
    "    \"Explain Article 7 and 8 in the format of contract agreement\": {\n",
    "        \"db62d004-20d7-4214-8f7e-b51fba1dc4f8\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# sanity: warn if any gold id not in current index\n",
    "all_node_ids = set(getattr(index.docstore, \"docs\", {}).keys())\n",
    "missing = [nid for ids in gold_ids_by_query.values() for nid in ids if nid not in all_node_ids]\n",
    "if missing:\n",
    "    print(\"Warning: some gold node_ids not present in the index:\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "15639796-e3aa-4303-a8d9-d34303d9cf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 13:26:44,942 - DEBUG - Building index from IDs objects\n"
     ]
    }
   ],
   "source": [
    "all_nodes = list(index.docstore.docs.values())\n",
    "\n",
    "# Global BM25 retriever (no filtering)\n",
    "bm25_all = BM25Retriever.from_defaults(nodes=all_nodes, similarity_top_k=16)\n",
    "\n",
    "def get_hits_no_meta(query: str, k_per: int = 16, final_top_n: int = 10, num_queries: int = 2):\n",
    "    \"\"\"\n",
    "    Metadata-agnostic retriever:\n",
    "      - vector (global FAISS) + BM25 (global) -> fusion\n",
    "      - optional small LLM-based expansion via num_queries\n",
    "      - cross-encoder reranker\n",
    "    \"\"\"\n",
    "    vec = index.as_retriever(similarity_top_k=k_per)\n",
    "\n",
    "    fusion = QueryFusionRetriever(\n",
    "        retrievers=[vec, bm25_all],\n",
    "        llm=Settings.llm,               # Gemini\n",
    "        similarity_top_k=k_per,\n",
    "        num_queries=num_queries,     \n",
    "        mode=\"reciprocal_rerank\",\n",
    "    )\n",
    "\n",
    "    # Retrieve\n",
    "    hits = fusion.retrieve(query) or []\n",
    "\n",
    "    # Rerank (no metadata filtering)\n",
    "    reranker = SentenceTransformerRerank(\n",
    "        model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\",\n",
    "        top_n=final_top_n,\n",
    "    )\n",
    "    hits = reranker.postprocess_nodes(hits, query_bundle=QueryBundle(query_str=query))\n",
    "    return hits  # list[NodeWithScore]\n",
    "\n",
    "def _node_id_of(hit):\n",
    "    node = getattr(hit, \"node\", hit)\n",
    "    return getattr(node, \"node_id\", None) or getattr(node, \"id_\", None)\n",
    "\n",
    "def preview_no_meta(query: str, top_k: int = 10, k_per: int = 16, num_queries: int = 2):\n",
    "    hits = get_hits_no_meta(query, k_per=k_per, final_top_n=top_k, num_queries=num_queries)\n",
    "    for i, h in enumerate(hits, 1):\n",
    "        node = h.node\n",
    "        nid = _node_id_of(h)\n",
    "        txt = (node.get_content() or \"\").replace(\"\\n\", \" \")[:300]\n",
    "        print(f\"{i}. id={nid} score={getattr(h,'score',None)}\")\n",
    "        print(txt, \"\\n\" + \"-\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "4b49c1ea-e4fc-4a5b-a37b-83bd44b30226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb2f7d96bb942a2a293e547a2e52e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dee18b032274c28a88e1e31a2a18672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1b33a56bbf4fefa24922ecc7b95c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c48d406a914a54be108d539e9cfa6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec42b4c95764655ac509ff4f0649271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa8d4c9dcb44e52b4582c7e332228f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fb0c19ba264b04bb4675e8ee8da70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d82080e0ed499fb7e69e414ef13ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c953db3cf4fb46dd8cd12f235ba55c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6696cb4dde4517921e0cf2b691fd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf38fa899e41446d82acfa09cd93b66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806f3914e5c546a88b386b23018dc35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ac7d28d8c64661b0f219587e58582c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9e142622534ca6bbd4fd35d42df328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9494ff29cde24c3f80eef65a9082956a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_eval': 15, 'MRR': 0.8541, 'Recall@1': 0.6, 'HitRate@1': 0.8, 'Recall@3': 0.6889, 'HitRate@3': 0.8667, 'Recall@5': 0.8111, 'HitRate@5': 0.9333, 'Recall@8': 0.8444, 'HitRate@8': 0.9333, 'Recall@10': 0.8667, 'HitRate@10': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def eval_retrieval_no_meta(\n",
    "    queries,\n",
    "    gold_ids_by_query,\n",
    "    Ks=(1,3,5,10),\n",
    "    k_per: int = 16,\n",
    "    final_top_n: int = 10,\n",
    "    num_queries: int = 2,     # set 1 to avoid LLM expansion cost during eval\n",
    "):\n",
    "    Ks = sorted(set(Ks))\n",
    "    maxK = max(Ks)\n",
    "    final_top_n = max(final_top_n, maxK)\n",
    "\n",
    "    recall_at = defaultdict(float)\n",
    "    hit_at = defaultdict(float)\n",
    "    mrr_sum = 0.0\n",
    "    n_eval = 0\n",
    "\n",
    "    for q in queries:\n",
    "        gold = set(gold_ids_by_query.get(q, []))\n",
    "        if not gold:\n",
    "            continue\n",
    "        n_eval += 1\n",
    "\n",
    "        hits = get_hits_no_meta(q, k_per=k_per, final_top_n=final_top_n, num_queries=num_queries)\n",
    "        ranked_ids = [_node_id_of(h) for h in hits if _node_id_of(h)]\n",
    "\n",
    "        # MRR\n",
    "        rr = 0.0\n",
    "        for rank, nid in enumerate(ranked_ids, start=1):\n",
    "            if nid in gold:\n",
    "                rr = 1.0 / rank\n",
    "                break\n",
    "        mrr_sum += rr\n",
    "\n",
    "        # Recall@K and HitRate@K\n",
    "        for K in Ks:\n",
    "            topK = ranked_ids[:K]\n",
    "            retrieved_rel = sum(1 for nid in topK if nid in gold)\n",
    "            recall_at[K] += retrieved_rel / max(1, len(gold))\n",
    "            hit_at[K]    += 1.0 if retrieved_rel > 0 else 0.0\n",
    "\n",
    "    if n_eval == 0:\n",
    "        return {\"note\": \"no labeled queries\"}\n",
    "\n",
    "    out = {\"n_eval\": n_eval, \"MRR\": round(mrr_sum / n_eval, 4)}\n",
    "    for K in Ks:\n",
    "        out[f\"Recall@{K}\"] = round(recall_at[K] / n_eval, 4)\n",
    "        out[f\"HitRate@{K}\"] = round(hit_at[K] / n_eval, 4)\n",
    "    return out\n",
    "\n",
    "eval_queries = list(gold_ids_by_query.keys())\n",
    "\n",
    "metrics = eval_retrieval_no_meta(\n",
    "    eval_queries,\n",
    "    gold_ids_by_query,\n",
    "    Ks = (1,3,5,8,10),\n",
    "    k_per = 16,\n",
    "    final_top_n = 10,\n",
    "    num_queries = 2, \n",
    ")\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6137ec-f637-4fa5-8e04-f07978669edb",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eadfa3-680c-4633-a2e6-304b9b2b645c",
   "metadata": {},
   "source": [
    "We obtained a high MRR of 0.85 which implies that gold nodes appear at top most of the time. HitRate is also quite good as among 10 top-k, it is 100%, implying that retriever is able to get nodes containing answers everytime if we have top k nodes to consider. Recall could be improved, but after more indepth error analysis we found that it is tied to RAG Agents we made with you.com, specially the RAG_PageContinue which got confused in similar content pages when they were from different documents, as we improve on them Recall could be improved and reach level of HitRate and MMR. We can also use screenshots in llamaparse and apply multiple Parsers suited specifically for specific file types and tune specifically for them.\n",
    "\n",
    "With average latency of 20.5 seconds our RAG pipeline is able to answer questions on time, and while 2 out of 15 answers were incorrect, we had 100% relative numerical accuracy implying that Numerical Figures are being extracted as they appear in documents, with proper punctuation, decimals, and currency signs as needed. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
